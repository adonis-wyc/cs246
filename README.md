Since joining [Silicon Valley Hands On Programming meetup](http://www.meetup.com/HandsOnProgrammingEvents/), we gladly finished Edx/BerkeleyX [CS100.1x](https://www.edx.org/course/introduction-big-data-apache-spark-uc-berkeleyx-cs100-1x) and [CS190.1x](https://www.edx.org/course/scalable-machine-learning-uc-berkeleyx-cs190-1x). Now we switched gear to [Stanford CS246: Mining Massive Data Sets (Winter 2015)](http://web.stanford.edu/class/cs246/).

I am still paying [CodingBat in Java](http://codingbat.com/java), so the major solution posted here will be coded in [Apache Spark Python](https://spark.apache.org/docs/latest/api/python/pyspark.html), [Python MrJob Hadoop](https://github.com/Yelp/mrjob) and [Ruby-Spark](http://ondra-m.github.io/ruby-spark/). [Wget](https://en.wikipedia.org/wiki/Wget) and [cURL](https://en.wikipedia.org/wiki/CURL) in shell scripts will be used to fetch some practicing data.